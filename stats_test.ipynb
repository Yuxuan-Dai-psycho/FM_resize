{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from viz import viz_df_trans\n",
    "from scipy.stats import wilcoxon, chisquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_test(corr, ori_corr, resize, modality='meg'):\n",
    "\n",
    "    # if resize=='ratio':\n",
    "    #     stats_df = pd.DataFrame(index=list(corr.index), columns=list(corr.columns)[:-1])\n",
    "    # else:\n",
    "    stats_df = pd.DataFrame(index=list(corr.index), columns=list(corr.columns))\n",
    "\n",
    "    for rescale, col in corr.iteritems():\n",
    "        for layer_idx, scores in col.iteritems():\n",
    "            # if not (rescale == 'rescale=1' and resize == 'ratio'):\n",
    "            if modality == 'meg':\n",
    "                d = np.mean(scores, axis=0) - np.mean(ori_corr[layer_idx], axis=0)\n",
    "                if d.all() == 0:\n",
    "                    stats_df[rescale][layer_idx] = np.nan\n",
    "                else:\n",
    "                    w,p = wilcoxon(np.mean(scores, axis=0), np.mean(ori_corr[layer_idx], axis=0))\n",
    "                    if np.mean(d) > 0:\n",
    "                        stats_df[rescale][layer_idx] = p\n",
    "                    else:\n",
    "                        stats_df[rescale][layer_idx] = -p\n",
    "\n",
    "            elif modality == 'behavior':\n",
    "                d = scores.flatten() - ori_corr[layer_idx].flatten()\n",
    "                if d.all() == 0:\n",
    "                    stats_df[rescale][layer_idx] = np.nan\n",
    "                else:\n",
    "                    w,p = wilcoxon(scores.flatten(), ori_corr[layer_idx].flatten())\n",
    "                    if np.mean(d) > 0:\n",
    "                        stats_df[rescale][layer_idx] = p\n",
    "                    else:\n",
    "                        stats_df[rescale][layer_idx] = -p\n",
    "\n",
    "            elif modality == 'fmri':\n",
    "                stats_dict = {'evc':stats_df, 'hvc':stats_df}\n",
    "                for i, roi in enumerate(['evc', 'hvc']):\n",
    "                    d = scores[:,i] - ori_corr[layer_idx][:,i]\n",
    "                    if d.all() == 0:\n",
    "                        stats_df[rescale][layer_idx] = np.nan\n",
    "                    else:\n",
    "                        w,p = wilcoxon(scores[:,i], ori_corr[layer_idx][:,i])\n",
    "                        if np.mean(d) > 0:\n",
    "                            stats_dict[roi][rescale][layer_idx] = p\n",
    "                        else:\n",
    "                            stats_dict[roi][rescale][layer_idx] = -p\n",
    "\n",
    "    if modality == 'fmri':\n",
    "        return stats_dict\n",
    "    else:\n",
    "        return stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### two-sided wilcoxon signed-rank test for each conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = np.arange(1, 6)\n",
    "datasets_n = [92, 118]\n",
    "modalities = ['meg', 'fmri', 'behavior']\n",
    "resize_type = ['ratio', 'fixed']\n",
    "dataset_root = '/LOCAL/ydai/workingdir/dataset'\n",
    "results_root = '/LOCAL/ydai/workingdir/resizing_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# meg data\n",
    "meg_sig_test = {}\n",
    "for resize in resize_type:\n",
    "    meg_sig_test[resize] = {}\n",
    "    for set_idx in datasets_n:\n",
    "    \n",
    "        meg_dir = pjoin(results_root, 'meg')\n",
    "        ori_corr = pd.read_pickle(pjoin(meg_dir, f'dataset{set_idx}_ratio_corr.pkl'))\n",
    "        ori_corr = ori_corr.iloc[:,-1]\n",
    "\n",
    "        corr_fn = f'dataset{set_idx}_{resize}_corr.pkl'\n",
    "        corr = pd.read_pickle(pjoin(meg_dir, corr_fn))\n",
    "        \n",
    "        meg_sig_test[resize][f'dataset{set_idx}'] = sig_test(corr, ori_corr, resize, modality='meg')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmri data\n",
    "fmri_sig_test = {}\n",
    "for resize in resize_type:\n",
    "    fmri_sig_test[resize] = {}\n",
    "    for set_idx in datasets_n:\n",
    "        fmri_dir = pjoin(results_root, 'fmri')\n",
    "        ori_corr = pd.read_pickle(pjoin(fmri_dir, f'dataset{set_idx}_ratio_corr.pkl'))\n",
    "        ori_corr = ori_corr.iloc[:,-1]\n",
    "\n",
    "        corr_fn = f'dataset{set_idx}_{resize}_corr.pkl'\n",
    "        corr = pd.read_pickle(pjoin(fmri_dir, corr_fn))\n",
    "\n",
    "        fmri_sig_test[resize][f'dataset{set_idx}'] = sig_test(corr, ori_corr, resize, modality='fmri')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# behavior data\n",
    "behavior_sig_test = {}\n",
    "for resize in resize_type:\n",
    "    behavior_sig_test[resize] = {}\n",
    "    for set_idx in datasets_n:\n",
    "        behavior_dir = pjoin(results_root, 'behavior')\n",
    "        ori_corr = pd.read_pickle(pjoin(behavior_dir, f'dataset{set_idx}_ratio_corr.pkl'))\n",
    "        ori_corr = ori_corr.iloc[:,-1]\n",
    "        \n",
    "        corr_fn = f'dataset{set_idx}_{resize}_corr.pkl'\n",
    "        corr = pd.read_pickle(pjoin(behavior_dir, corr_fn))\n",
    "\n",
    "        behavior_sig_test[resize][f'dataset{set_idx}'] = sig_test(corr, ori_corr, resize, modality='behavior')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive Statistical Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.00% of downsampling cases lead to significant improvments, chi-square score=9.68, p=0.002\n"
     ]
    }
   ],
   "source": [
    "# test all conditions\n",
    "n_cond = 0\n",
    "n_pos_sig = 0\n",
    "for set_idx in datasets_n:\n",
    "    meg_df = meg_sig_test['ratio'][f'dataset{set_idx}']\n",
    "    fmri_df = fmri_sig_test['ratio'][f'dataset{set_idx}']\n",
    "    behavior_df = behavior_sig_test['ratio'][f'dataset{set_idx}']\n",
    "\n",
    "    n_cond += meg_df.size - meg_df.isna().sum().sum()\n",
    "    n_cond += behavior_df.size - behavior_df.isna().sum().sum()\n",
    "    n_cond += fmri_df['evc'].size - fmri_df['evc'].isna().sum().sum()\n",
    "    n_cond += fmri_df['hvc'].size - fmri_df['hvc'].isna().sum().sum()\n",
    "\n",
    "    n_pos_sig += meg_df[(meg_df>0) & (meg_df<0.05)].count().sum()\n",
    "    n_pos_sig += behavior_df[(behavior_df>0) & (behavior_df<0.05)].count().sum()\n",
    "    n_pos_sig += fmri_df['evc'][(fmri_df['evc']>0) & (fmri_df['evc']<0.05)].count().sum()\n",
    "    n_pos_sig += fmri_df['hvc'][(fmri_df['hvc']>0) & (fmri_df['hvc']<0.05)].count().sum()\n",
    "\n",
    "chisq, p = chisquare([n_pos_sig, n_cond-n_pos_sig])\n",
    "\n",
    "print('{:.2f}% of downsampling cases lead to significant improvments, chi-square score={:.2f}, p={:.3f}'.format(n_pos_sig/n_cond*100, chisq, p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.00% of downsampling cases of fmri data lead to improvments, chi-square score=51.84, p=0.000\n"
     ]
    }
   ],
   "source": [
    "# consider fmri data only\n",
    "n_cond = 0\n",
    "n_pos_sig = 0\n",
    "for set_idx in datasets_n:\n",
    "    fmri_df = fmri_sig_test['ratio'][f'dataset{set_idx}']\n",
    "\n",
    "    n_cond += fmri_df['evc'].size - fmri_df['evc'].isna().sum().sum()\n",
    "    n_cond += fmri_df['hvc'].size - fmri_df['hvc'].isna().sum().sum()\n",
    "\n",
    "    n_pos_sig += fmri_df['evc'][fmri_df['evc']>0].count().sum()\n",
    "    n_pos_sig += fmri_df['hvc'][fmri_df['hvc']>0].count().sum()\n",
    "\n",
    "chisq, p = chisquare([n_pos_sig, n_cond-n_pos_sig])\n",
    "\n",
    "print('{:.2f}% of downsampling cases of fmri data lead to improvments, chi-square score={:.2f}, p={:.3f}'.format(n_pos_sig/n_cond*100, chisq, p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsampling features to 25% causes improvments in 85.00% of cases, chi-square score=19.60, p=0.000\n"
     ]
    }
   ],
   "source": [
    "# consider 25% downsampling only\n",
    "n_cond = 0\n",
    "n_pos_sig = 0\n",
    "for set_idx in datasets_n:\n",
    "    meg_df = meg_sig_test['ratio'][f'dataset{set_idx}']['rescale=0.25']\n",
    "    fmri_df = fmri_sig_test['ratio'][f'dataset{set_idx}']\n",
    "    behavior_df = behavior_sig_test['ratio'][f'dataset{set_idx}']['rescale=0.25']\n",
    "\n",
    "    n_cond += meg_df.size - meg_df.isna().sum()\n",
    "    n_cond += behavior_df.size - behavior_df.isna().sum()\n",
    "    n_cond += fmri_df['evc']['rescale=0.25'].size - fmri_df['evc']['rescale=0.25'].isna().sum()\n",
    "    n_cond += fmri_df['hvc']['rescale=0.25'].size - fmri_df['hvc']['rescale=0.25'].isna().sum()\n",
    "\n",
    "    n_pos_sig += meg_df[meg_df>0].count().sum()\n",
    "    n_pos_sig += behavior_df[behavior_df>0].count().sum()\n",
    "    n_pos_sig += fmri_df['evc']['rescale=0.25'][(fmri_df['evc']['rescale=0.25']>0)].count().sum()\n",
    "    n_pos_sig += fmri_df['hvc']['rescale=0.25'][(fmri_df['hvc']['rescale=0.25']>0)].count().sum()\n",
    "\n",
    "chisq, p = chisquare([n_pos_sig, n_cond-n_pos_sig])\n",
    "\n",
    "print('downsampling features to 25% causes improvments in {:.2f}% of cases, chi-square score={:.2f}, p={:.3f}'.format(n_pos_sig/n_cond*100, chisq, p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For features from layer1, downsampling leads improvments in 80.00% of cases, chi-square score=14.40, p=0.000\n"
     ]
    }
   ],
   "source": [
    "# consider downsampling for layer1 only\n",
    "n_cond = 0\n",
    "n_pos_sig = 0\n",
    "for set_idx in datasets_n:\n",
    "    meg_df = meg_sig_test['ratio'][f'dataset{set_idx}'].iloc[0,:]\n",
    "    fmri_df = fmri_sig_test['ratio'][f'dataset{set_idx}']\n",
    "    behavior_df = behavior_sig_test['ratio'][f'dataset{set_idx}'].iloc[0,:]\n",
    "\n",
    "    n_cond += meg_df.size - meg_df.isna().sum()\n",
    "    n_cond += behavior_df.size - behavior_df.isna().sum()\n",
    "    n_cond += fmri_df['evc'].iloc[0,:].size - fmri_df['evc'].iloc[0,:].isna().sum()\n",
    "    n_cond += fmri_df['hvc'].iloc[0,:].size - fmri_df['hvc'].iloc[0,:].isna().sum()\n",
    "\n",
    "    n_pos_sig += meg_df[meg_df>0].count().sum()\n",
    "    n_pos_sig += behavior_df[behavior_df>0].count().sum()\n",
    "    n_pos_sig += fmri_df['evc'].iloc[0,:][(fmri_df['evc'].iloc[0,:]>0)].count().sum()\n",
    "    n_pos_sig += fmri_df['hvc'].iloc[0,:][(fmri_df['hvc'].iloc[0,:]>0)].count().sum()\n",
    "\n",
    "chisq, p = chisquare([n_pos_sig, n_cond-n_pos_sig])\n",
    "\n",
    "print('For features from layer1, downsampling leads improvments in {:.2f}% of cases, chi-square score={:.2f}, p={:.3f}'.format(n_pos_sig/n_cond*100, chisq, p))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fbba547a53313e93f0b894e25afed926464e03c4ab0dfdd49f12f056cd86d4f"
  },
  "kernelspec": {
   "display_name": "Python [conda env:python38]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
